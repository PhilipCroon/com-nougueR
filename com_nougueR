# ============================================================
# Written by: Philip M. Croon
# philip.croon@yale.edu / p.croon@amsterdamumc.nl
# Implements: Com–Nougué et al. (1993) equivalence framework
#   How to establish equivalence when data are censored:
#   A randomized trial of treatments for B non‑Hodgkin lymphoma
#   C. Com‑Nougué, C. Rodary, C. Patte
#   Statistics in Medicine, First published: 30 July 1993
#   DOI: 10.1002/sim.4780121407  (Yale links • PDF)
# ============================================================

suppressPackageStartupMessages({
  library(survival)
  library(readxl)
})

# ---- User inputs -------------------------------------------------------------

# Path to Excel
path <- %ADD ROOT
file_new <- file.path(path, "XXXXXXXX.csv") #ADD FILENAME

# Column names in the Excel sheet
RAND_COL  <- "Randomization Group (0 = C, 1 = I)"  # 0 = control, 1 = intervention
TIME_COL  <- "time_to_event_or_end_of_study"        # analysis time variable
EVENT_COL <- "outcome_af"                           # 1 = event, 0 = censored

# Time horizon T (days) for the point estimate/CI, and confidence level
t_star <- 180
alpha  <- 0.05
z      <- qnorm(1 - alpha/2)  # 1.96 for 95% two-sided

# Output files
out_lt_int  <- file.path(path, "life_table_intervention.csv")
out_lt_ctrl <- file.path(path, "life_table_control.csv")

# ---- Load & tidy ------------------------------------------------------------

df <- read_excel(file_new)
colnames(df) <- trimws(colnames(df))

stopifnot(all(c(RAND_COL, TIME_COL, EVENT_COL) %in% names(df)))
df <- df[, c(RAND_COL, TIME_COL, EVENT_COL)]
df <- df[complete.cases(df), ]

# Ensure numeric, start counting at day 1, and clip follow-up at T
df[[TIME_COL]]  <- as.numeric(df[[TIME_COL]]) + 1
df[[EVENT_COL]] <- as.numeric(df[[EVENT_COL]])
df[[TIME_COL]]  <- pmin(df[[TIME_COL]], t_star)

# Split arms
interv <- subset(df, df[[RAND_COL]] == 1)
ctrl   <- subset(df, df[[RAND_COL]] == 0)

if (nrow(interv) == 0 || nrow(ctrl) == 0) {
  stop("One of the groups has zero rows after filtering. Check RAND_COL values (0/1).")
}

# ---- Kaplan–Meier fits (one‑group each) ------------------------------------

sf_int  <- survfit(Surv(interv[[TIME_COL]], interv[[EVENT_COL]]) ~ 1, conf.type = "plain")
sf_ctrl <- survfit(Surv(ctrl[[TIME_COL]],   ctrl[[EVENT_COL]])   ~ 1, conf.type = "plain")

sum_int  <- summary(sf_int)
sum_ctrl <- summary(sf_ctrl)

lt_int  <- data.frame(sum_int[c("time", "n.risk", "n.event", "n.censor", "surv", "std.err")])
lt_ctrl <- data.frame(sum_ctrl[c("time", "n.risk", "n.event", "n.censor", "surv", "std.err")])

# Helper: take KM step just before or at T, with Greenwood SE
km_at_T <- function(lt, T) {
  ltT <- lt[lt$time <= T, ]
  if (nrow(ltT) == 0) {
    # No events before T: survival = 1, Greenwood SE = 0
    return(list(S = 1, se = 0))
  }
  last <- ltT[nrow(ltT), ]
  list(S = as.numeric(last$surv), se = as.numeric(last$std.err))
}

int_T  <- km_at_T(lt_int,  t_star)
ctrl_T <- km_at_T(lt_ctrl, t_star)

S_int  <- int_T$S
S_ctrl <- ctrl_T$S
se_Si  <- int_T$se       # Greenwood SE of S_int(T)
se_Sc  <- ctrl_T$se      # Greenwood SE of S_ctrl(T)

# Guard very small survival values to keep logs well-defined
eps   <- 1e-12
S_int <- max(min(S_int, 1 - eps), eps)
S_ctrl <- max(min(S_ctrl, 1 - eps), eps)

# ---- Com–Nougué eq. (9): CI for Δ = S_control(T) − S_intervention(T) -------

Delta     <- S_ctrl - S_int
se_Delta  <- sqrt(se_Sc^2 + se_Si^2)  # Greenwood: var difference ≈ sum of vars
Delta_lo  <- Delta - z * se_Delta
Delta_hi  <- Delta + z * se_Delta

# ---- Com–Nougué eq. (6) and (10): r = log(SN) / log(SS), CI via transform ---

# r-hat
r_hat <- log(S_int) / log(S_ctrl)

# Transform Δ-interval to an interval for S_int(T), then map to r via r = log(SN)/log(SS)
# S_N(T) = S_ctrl(T) - Δ  (algebraic rearrangement)
SN_lo <- max(min(S_ctrl - Delta_hi, 1 - eps), eps)  # “worst” (smallest) SN from upper Δ
SN_hi <- max(min(S_ctrl - Delta_lo, 1 - eps), eps)  # “best”  (largest)  SN from lower Δ

r_lo <- log(SN_lo) / log(S_ctrl)
r_hi <- log(SN_hi) / log(S_ctrl)

# Note: the mapping is monotone in SN for fixed SS in (0,1), so [r_lo, r_hi] is valid.

# ---- Also report cumulative incidence (1 − S) and its RD for reference ------

CI_int  <- 1 - S_int
CI_ctrl <- 1 - S_ctrl

RD_ci     <- CI_int - CI_ctrl          # = (1 − S_int) − (1 − S_ctrl) = S_ctrl − S_int = Δ
RD_ci_lo  <- Delta_lo
RD_ci_hi  <- Delta_hi

# ---- Print summary ----------------------------------------------------------

cat(sprintf(
  "\nAt %d days (Kaplan–Meier, Greenwood SE):\n", t_star
))
cat(sprintf("  Survival           — Intervention: %6.2f%%  |  Control: %6.2f%%\n",
            100*S_int, 100*S_ctrl))
cat(sprintf("  Cumulative incidence — Intervention: %6.2f%%  |  Control: %6.2f%%\n\n",
            100*CI_int, 100*CI_ctrl))

cat(sprintf(
  "Difference in survival Δ = S_control − S_intervention @%d days: %+.2f%% (95%% CI %+.2f%% to %+.2f%%)\n",
  t_star, 100*Delta, 100*Delta_lo, 100*Delta_hi
))


# ---- Append summary rows to life tables and export --------------------------

add_note_row <- function(lt, T, S_T, se_T, txt) {
  out <- lt
  out$note <- NA_character_
  note_row <- data.frame(
    time     = T,
    n.risk   = NA, n.event = NA, n.censor = NA,
    surv     = S_T,
    std.err  = se_T,
    note     = txt,
    check.names = FALSE
  )
  rbind(out, note_row)
}

note_int  <- sprintf("ΔS(Control−Intervention) %+.2f%% (95%% %+.2f to %+.2f); r̂=%.3f (95%% %.3f–%.3f)",
                     100*Delta, 100*Delta_lo, 100*Delta_hi, r_hat, r_lo, r_hi)
note_ctrl <- sprintf("CumInc RD (I−C) %+.2f%% (95%% %+.2f to %+.2f)",
                     100*RD_ci, 100*RD_ci_lo, 100*RD_ci_hi)

lt_int_out  <- add_note_row(lt_int,  t_star, S_int,  se_Si, note_int)
lt_ctrl_out <- add_note_row(lt_ctrl, t_star, S_ctrl, se_Sc, note_ctrl)

write.csv(lt_int_out,  out_lt_int,  row.names = FALSE)
write.csv(lt_ctrl_out, out_lt_ctrl, row.names = FALSE)

# ---- Done -------------------------------------------------------------------
